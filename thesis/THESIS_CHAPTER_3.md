# РОЗДІЛ 3. ПРОЕКТУВАННЯ ПРОГРАМНОГО ЗАБЕЗПЕЧЕННЯ ДЛЯ АВТОМАТИЗОВАНОГО АНАЛІЗУ XRD-КРИВИХ

## 3.1. Загальна структура програмної системи

### 3.1.1. Концептуальна архітектура системи

Розроблене програмне забезпечення реалізує повний цикл від генерації синтетичних навчальних даних до визначення структурних параметрів реальних експериментальних зразків методами глибокого навчання. Архітектура системи базується на модульному принципі з чітким розділенням відповідальності між компонентами та мінімізацією зв'язності між модулями. Концептуально система складається з чотирьох основних підсистем: підсистема моделювання фізичних процесів, підсистема підготовки даних, підсистема машинного навчання та підсистема інференсу та візуалізації результатів.

Підсистема моделювання фізичних процесів інкапсулює реалізацію динамічної теорії дифракції в формулюванні Такагі-Таупіна та відповідає за чисельне розв'язання диференціальних рівнянь, що описують еволюцію хвильового поля рентгенівського випромінювання в кристалі з градієнтом параметра ґратки. Центральним класом цієї підсистеми є HRXRDSimulator, що реалізує рекурсивний метод обчислення амплітуд розсіяння для багатошарової системи. Підсистема також включає класи-контейнери для параметрів кристалу (CrystalParameters), плівки (FilmParameters), геометрії експерименту (GeometryParameters) та профілю деформації (DeformationProfile), що забезпечує типобезпечність та валідацію вхідних даних на етапі конструювання об'єктів.

Підсистема підготовки даних відповідає за генерацію великомасштабних навчальних датасетів шляхом системного варіювання структурних параметрів у фізично допустимих діапазонах та виклику підсистеми моделювання для обчислення відповідних кривих дифракційного відбивання. Ключовою особливістю цієї підсистеми є реалізація методу стратифікованого семплювання, що забезпечує рівномірний розподіл критичних параметрів (зокрема товщини дефектного шару L2) у навчальній вибірці. Підсистема також виконує попередню обробку даних: логарифмічне перетворення інтенсивностей для компресії динамічного діапазону, нормалізацію до стандартизованого діапазону [0, 1] та усічення нейнформативних ділянок кривої. Паралелізація обчислень реалізована через модуль multiprocessing стандартної бібліотеки Python з динамічним розподілом навантаження між процесорними ядрами.

Підсистема машинного навчання інкапсулює архітектуру згорткової нейронної мережі, функції втрат з фізичними обмеженнями, алгоритми оптимізації та логіку циклу навчання. Архітектура базується на фреймворку PyTorch, що забезпечує автоматичне диференціювання для обчислення градієнтів, ефективну роботу з тензорними операціями на графічних процесорах та зручні абстракції для побудови та композиції шарів нейронних мереж. Центральний клас XRDRegressor інкапсулює топологію мережі через композицію стандартних модулів PyTorch (згорткові шари, пакетна нормалізація, активаційні функції) та власних компонентів (механізм уваги, залишкові блоки з розширеними згортками). Підсистема також включає класи для завантаження та аугментації даних (NormalizedXRDDataset), обчислення метрик якості та збереження контрольних точок моделі.

Підсистема інференсу та візуалізації забезпечує застосування навченої моделі до експериментальних даних, денормалізацію передбачених параметрів до фізичних одиниць, обчислення профілю деформації на основі передбачених параметрів для порівняння з експериментом та візуалізацію результатів у формі графіків кривих дифракційного відбивання та профілів деформації. Ця підсистема розроблена з урахуванням можливості інтеграції з експериментальними установками для аналізу в режимі реального часу під час вимірювання рентгенівських даних.

Взаємодія між підсистемами організована за принципом однонаправлених залежностей: підсистема підготовки даних залежить від підсистеми моделювання фізичних процесів, підсистема машинного навчання залежить від підсистеми підготовки даних (через інтерфейс завантаження датасетів), а підсистема інференсу залежить від підсистеми машинного навчання (через інтерфейс завантаження натренованої моделі) та опціонально від підсистеми моделювання (для генерації теоретичних кривих за передбаченими параметрами). Така організація забезпечує можливість незалежної розробки та тестування кожної підсистеми, а також спрощує модифікацію та розширення функціональності.

### 3.1.2. Діаграма компонентів системи

Діаграма компонентів верхнього рівня відображає структурну організацію програмної системи та інтерфейси взаємодії між основними модулями:

```
┌─────────────────────────────────────────────────────────────────┐
│                    XRD Analysis System                          │
└─────────────────────────────────────────────────────────────────┘
                              │
        ┌─────────────────────┼─────────────────────┐
        │                     │                     │
        ▼                     ▼                     ▼
┌──────────────┐    ┌──────────────────┐   ┌───────────────┐
│   Physical   │    │  Data Pipeline   │   │   ML Core     │
│  Simulation  │───▶│   & Preprocessing│──▶│   & Training  │
└──────────────┘    └──────────────────┘   └───────────────┘
        │                     │                     │
        │                     │                     ▼
        │                     │            ┌────────────────┐
        │                     │            │  Model         │
        │                     │            │  Checkpoints   │
        │                     │            └────────────────┘
        │                     │                     │
        └─────────────────────┴─────────────────────┼────────┐
                                                    │        │
                                                    ▼        ▼
                                            ┌──────────────────────┐
                                            │  Inference &         │
                                            │  Visualization       │
                                            └──────────────────────┘
                                                    │
                                                    ▼
                                            ┌──────────────┐
                                            │ Experimental │
                                            │    Data      │
                                            └──────────────┘
```

Компонент Physical Simulation (модуль xrd.py) надає інтерфейс compute_curve_and_profile, що приймає набір структурних параметрів та повертає обчислену криву дифракційного відбивання разом з профілем деформації. Внутрішньо компонент складається з класів HRXRDSimulator (ядро обчислень), CrystalParameters, FilmParameters, GeometryParameters (параметри задачі) та DeformationProfile (профіль деформації). Компонент не має зовнішніх залежностей окрім стандартної бібліотеки NumPy для чисельних обчислень.

Компонент Data Pipeline включає модулі dataset_stratified.py для генерації датасетів з стратифікованим семплюванням та dataset.py для базової генерації з випадковим семплюванням. Ключовим інтерфейсом є функція generate_stratified_dataset, що повертає пару тензорів PyTorch (X, Y), де X містить нормалізовані параметри, Y – нормалізовані криві. Компонент залежить від Physical Simulation для генерації кривих та використовує модуль multiprocessing для паралельної генерації великих обсягів даних.

Компонент ML Core інкапсулює архітектуру нейронної мережі (модуль model_common.py) та процес навчання (model_train.py). Центральний клас XRDRegressor наслідується від nn.Module фреймворку PyTorch та реалізує інтерфейси forward для прямого проходу (inference) та властивості parameters для доступу до ваг моделі. Додаткові класи включають ResidualBlock (багаторазово використовуваний компонент), AttentionPool1d (механізм уваги), NormalizedXRDDataset (адаптер для завантаження даних з формату pickle до PyTorch DataLoader). Функція physics_constrained_loss реалізує фізично-інформовану функцію втрат.

Компонент Inference & Visualization (model_evaluate.py та допоміжні модулі) використовує натреновану модель для передбачення параметрів експериментальних зразків. Інтерфейс evaluate_model приймає шлях до checkpoint файлу моделі та датасет для оцінки, повертає словник з метриками якості (MAE, MAE%, кореляції тощо). Додатковий інтерфейс predict_single_curve призначений для аналізу окремих експериментальних кривих у виробничому використанні.

### 3.1.3. Апаратні вимоги та розгортання системи

Система спроектована для роботи як на високопродуктивних обчислювальних кластерах для етапу навчання моделі, так і на звичайних робочих станціях для етапу інференсу та аналізу експериментальних даних. Мінімальні апаратні вимоги для повного циклу розробки та навчання включають: багатоядерний процесор (рекомендовано 8+ фізичних ядер для ефективної паралелізації генерації датасетів), оперативну пам'ять обсягом мінімум 32 ГБ (для завантаження в пам'ять датасетів розміром до 1 мільйона зразків), графічний процесор з підтримкою CUDA або Metal (Apple Silicon) та відеопам'яттю мінімум 8 ГБ для навчання моделі версії v3 з batch size 256, сховище даних з швидким доступом (SSD) обсягом мінімум 500 ГБ для збереження датасетів та контрольних точок моделі.

Для етапу інференсу (застосування натренованої моделі до експериментальних даних) вимоги значно нижчі: будь-який сучасний процесор, 8 ГБ оперативної пам'яті, відеокарта не є обов'язковою (inference на CPU займає менше 1 секунди на криву). Це дозволяє розгорнути підсистему інференсу безпосередньо на комп'ютерах, підключених до експериментальних рентгенівських дифрактометрів, для аналізу в режимі реального часу.

Програмна платформа базується на Python версії 3.10 або вище з наступними ключовими залежностями: PyTorch 2.0+ (фреймворк глибокого навчання), NumPy 1.24+ (чисельні обчислення), Matplotlib 3.7+ (візуалізація), tqdm (індикатори прогресу). Розгортання здійснюється через стандартний механізм віртуальних середовищ Python (venv або conda) з декларативним описом залежностей у файлі requirements.txt. Для кросплатформенної сумісності всі шляхи до файлів обробляються через модуль pathlib, що забезпечує коректну роботу на Windows, Linux та macOS.

Для прискорення обчислень на графічних процесорах система автоматично детектує доступні апаратні прискорювачі через функцію get_device: якщо доступна CUDA (NVIDIA GPU), використовується torch.device('cuda'); якщо доступна Metal Performance Shaders (Apple Silicon), використовується torch.device('mps'); інакше використовується torch.device('cpu'). Така гнучкість забезпечує оптимальну продуктивність на різних апаратних конфігураціях без модифікації коду.

## 3.2. Архітектура підсистеми моделювання фізичних процесів

### 3.2.1. Структура класів для моделювання дифракції

Підсистема моделювання організована навколо класу HRXRDSimulator, що інкапсулює повну логіку обчислення кривої дифракційного відбивання методом динамічної теорії дифракції. Клас розроблений з дотриманням принципу єдиної відповідальності (Single Responsibility Principle): він відповідає виключно за фізичні обчислення, делегуючи управління даними до класів-контейнерів параметрів та профілів. Діаграма класів підсистеми моделювання має наступну структуру:

```
┌─────────────────────────┐
│  CrystalParameters      │
├─────────────────────────┤
│ + a: float             │  Параметр ґратки
│ + h, k, l: int         │  Індекси Міллера
│ + Lambda: float        │  Довжина хвилі
│ + ChiR0, ChiI0: float  │  Поляризовність
│ + ChiRH, ChiIH: float  │  Фур'є-компонента
│ + ModChiIH: ndarray    │  Уявна частина (σ, π)
│ + Nu: float            │  Коефіцієнт Пуассона
└─────────────────────────┘
           │
           │ uses
           ▼
┌─────────────────────────┐
│  FilmParameters         │
├─────────────────────────┤
│ + a: float             │  Параметр ґратки плівки
│ + h, k, l: int         │  Індекси Міллера
│ + hpl: float           │  Товщина плівки
│ + Lambda: float        │
│ + ChiR0pl, ChiI0pl     │
│ + ChiRHpl, ChiIHpl     │
│ + ModChiIHpl: ndarray  │
└─────────────────────────┘
           │
           │ uses
           ▼
┌─────────────────────────┐
│  GeometryParameters     │
├─────────────────────────┤
│ + psi: float           │  Кут азимуту
│ + asymmetric: bool     │  Асиметрична геометрія?
└─────────────────────────┘
           │
           │ uses
           ▼
┌─────────────────────────────────────┐
│  DeformationProfile                 │
├─────────────────────────────────────┤
│ + Dmax1, D01: float                │  Асиметрична гаусіана
│ + L1, Rp1: float                   │
│ + D02, L2, Rp2: float              │  Спадна гаусіана
│ + Dmin: float                      │  Мінімальна деформація
│ + dl: float                        │  Товщина підшару
├─────────────────────────────────────┤
│ + validate_constraints(): bool     │  Перевірка фізичних обмежень
│ + compute_at_depth(z: float): float│ Значення деформації на глибині z
└─────────────────────────────────────┘
           │
           │ uses
           ▼
┌──────────────────────────────────────────────────────┐
│  HRXRDSimulator                                      │
├──────────────────────────────────────────────────────┤
│ - crystal: CrystalParameters                         │
│ - film: FilmParameters                               │
│ - geometry: GeometryParameters                       │
│ - km: int                          # кількість шарів │
│ - DD: ndarray                      # профіль деформації │
│ - DeltaTeta: ndarray               # кутова сітка    │
│ - R_cogerTT: ndarray               # когерентна інтенсивність │
│ - R_vseZ: ndarray                  # повна інтенсивність │
├──────────────────────────────────────────────────────┤
│ + __init__(crystal, film, geometry)                 │
│ + Start(): void                    # Ініціалізація   │
│ + Profil(deformation): void        # Розрахунок профілю │
│ + PolarizationInit(): void         # Поляризаційні параметри │
│ + RozrachKogerTT(m1, m10, ik): void # Когерентна складова │
│ + Zgortka(m1, m10, ik): void       # Згортка з апаратною функцією │
│ + RunSimulation(deformation, m1, m10, ik): Tuple   │
└──────────────────────────────────────────────────────┘
           │
           │ creates
           ▼
┌─────────────────────────┐
│  Curve                  │
├─────────────────────────┤
│ + ML_X: ndarray        │  X для ML (індекси 0..649)
│ + ML_Y: ndarray        │  Y для ML (усічена крива)
│ + X_DeltaTeta: ndarray │  Фізичні кути (arcsec)
│ + Y_R_vseZ: ndarray    │  Повна інтенсівність
│ + Y_R_vse: ndarray     │  Когерентна інтенсівність
└─────────────────────────┘

┌─────────────────────────┐
│  Profile                │
├─────────────────────────┤
│ + X: ndarray           │  Глибина (Ångströms)
│ + total_Y: ndarray     │  Загальна деформація
│ + asymmetric_Y: ndarray│  Асиметрична компонента
│ + decaying_Y: ndarray  │  Спадна компонента
└─────────────────────────┘
```

Клас CrystalParameters є immutable data class, що зберігає кристалографічні та оптичні параметри субстрату. Всі поля є публічними константами, що ініціалізуються через конструктор з валідацією фізичної коректності (наприклад, параметр ґратки a має бути додатнім). Клас FilmParameters має аналогічну структуру для параметрів плівки з додатковим полем hpl (товщина плівки в см). Такий розділ на два класи замість одного узагальненого обумовлений різними фізичними властивостями: субстрат вважається ідеальним кристалом без деформацій, тоді як плівка може містити градієнти параметра ґратки.

Клас DeformationProfile інкапсулює параметри профілю деформації та надає методи для обчислення значення деформації на довільній глибині z через метод compute_at_depth. Метод validate_constraints перевіряє виконання фізичних обмежень (D01 ≤ Dmax1, L2 ≤ L1, D01 + D02 ≤ 0.03 тощо) та повертає булеве значення, що використовується для фільтрації некоректних комбінацій параметрів під час генерації датасетів. Внутрішньо метод compute_at_depth реалізує суперпозицію асиметричної та спадної гаусіан згідно з формулами, описаними в розділі 2.

Центральний клас HRXRDSimulator має складну внутрішню структуру з приватними полями для збереження проміжних результатів обчислень (амплітуди хвиль, фактори поляризації, матриці переходу між шарами) та публічними методами для виконання послідовних етапів симуляції. Метод Start ініціалізує параметри задачі та виділяє пам'ять для масивів. Метод Profil приймає об'єкт DeformationProfile та обчислює дискретний профіль деформації DD як масив значень у km точках, де km = int(L1 / dl) – кількість підшарів. Метод PolarizationInit обчислює поляризаційно-залежні параметри для кожного підшару на основі профілю DD.

Метод RozrachKogerTT реалізує рекурсивний алгоритм обчислення когерентної амплітуди розсіяння через послідовне застосування матриць переходу для кожного підшару та інтерференцію хвиль, відбитих від меж підшарів. Параметри m1, m10 та ik визначають дискретизацію кутової сітки: m1 – загальна кількість точок, m10 – кількість точок в околі піку Брегга з дрібнішою дискретизацією, ik – коефіцієнт згущення сітки. Метод Zgortka виконує згортку обчисленої когерентної інтенсивності з гаусовою інструментальною функцією для врахування кінцевого кутового розширення експериментальної установки.

Публічний метод RunSimulation є фасадом (Facade pattern), що викликає всі внутрішні методи в правильній послідовності та повертає кортеж з трьох масивів: кутова сітка в arcsec, когерентна інтенсивність та повна інтенсивність після згортки. Цей метод забезпечує простий інтерфейс для використання симулятора: клієнтський код не потребує знання про внутрішні етапи обчислень та порядок виклику методів. Функція верхнього рівня compute_curve_and_profile є ще одним фасадом, що створює екземпляри всіх необхідних класів (CrystalParameters, FilmParameters, GeometryParameters, HRXRDSimulator) з фіксованими параметрами для системи GGG + YIG, викликає RunSimulation та формує об'єкти Curve і Profile для зручного доступу до результатів.

### 3.2.2. Алгоритм рекурсивного розв'язку рівнянь Такагі-Таупіна

Центральний алгоритм підсистеми моделювання реалізує рекурсивний метод обчислення амплітуд дифрагованих хвиль для багатошарової системи. Алгоритм базується на розбитті неоднорідного деформованого шару на тонкі однорідні підшари товщиною dl, для кожного з яких аналітично розв'язуються диференціальні рівняння Такагі-Таупіна, та послідовному застосуванні умов неперервності електромагнітного поля на межах між підшарами. Блок-схема алгоритму представлена нижче:

```
START
  │
  ▼
┌────────────────────────────────────┐
│ Вхід: DeformationProfile,          │
│       m1, m10, ik (параметри сітки)│
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 1. Ініціалізація параметрів        │
│    Start()                         │
│    - Обчислення кутів Брегга       │
│    - Виділення пам'яті для масивів │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 2. Розрахунок профілю деформації   │
│    Profil(deformation)             │
│    FOR k = 1 TO km:                │
│      z = (km - k + 1) * dl - dl/2  │
│      DD[k] = deformation.          │
│              compute_at_depth(z)   │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 3. Ініціалізація поляризації       │
│    PolarizationInit()              │
│    FOR k = 1 TO km:                │
│      ChiI0_a[k] = f(DD[k])        │
│      Обчислення xhp_a, xhn_a       │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 4. Генерація кутової сітки         │
│    FOR i = 1 TO m1:                │
│      IF i ≤ m10:                   │
│        DeltaTeta[i] = dense grid   │
│      ELSE:                         │
│        DeltaTeta[i] = sparse grid  │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5. Цикл по кутовій сітці           │
│    FOR i = 1 TO m1:                │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.1. Обчислення для субстрату      │
│      alpha = DeltaTeta[i] + theta_B│
│      T_substrate = TransferMatrix( │
│                    alpha, chi_s)   │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.2. Рекурсія по шарах плівки      │
│      T_total = I (одинична матриця)│
│      FOR k = km DOWNTO 1:          │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.2.1. Обчислення параметрів шару k│
│        chi_k = chi0 + DD[k] * grad │
│        T_k = TransferMatrix(       │
│              alpha, chi_k, dl)     │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.2.2. Композиція матриць переходу │
│        T_total = T_total · T_k     │
│        (матричне множення)         │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.3. Обчислення амплітуд на поверхні│
│      [A_reflected] = T_total ·     │
│      [A_incident ] · T_substrate   │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 5.4. Обчислення інтенсивності      │
│      R_cogerTT[i] = |A_reflected|² │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ NEXT i (кінець циклу по кутах)     │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ 6. Згортка з апаратною функцією    │
│    Zgortka(m1, m10, ik)            │
│    H_gauss = Gaussian(FWHM)        │
│    R_vseZ = R_cogerTT ⊗ H_gauss    │
│    (операція згортки ⊗)            │
└────────────────────────────────────┘
  │
  ▼
┌────────────────────────────────────┐
│ Вихід: DeltaTeta, R_cogerTT, R_vseZ│
└────────────────────────────────────┘
  │
  ▼
END
```

Ключовим елементом алгоритму є обчислення матриці переходу TransferMatrix для кожного підшару, що описує зміну амплітуд падаючої та дифрагованої хвиль при проходженні через підшар товщиною dl. Матриця є розв'язком системи диференціальних рівнянь Такагі-Таупіна для однорідного середовища та має розмір 2×2 для симетричної геометрії (σ-поляризація) або 4×4 для загального випадку (σ та π поляризації). Елементи матриці залежать від кута відхилення від умови Брегга (alpha), фур'є-компонент поляризовності кристалу (chi) та товщини підшару (dl) через комбінації тригонометричних та експоненційних функцій.

Рекурсивна композиція матриць переходу (крок 5.2.2) реалізує принцип суперпозиції хвиль: загальна амплітуда на виході з багатошарової системи є результатом послідовного розсіяння хвилі в кожному шарі з урахуванням інтерференції між хвилями, відбитими від різних меж. Математично це виражається як добуток матриць: T_total = T_km · T_km-1 · ... · T_2 · T_1, де порядок множення відповідає проходженню хвилі від поверхні вглиб кристалу. Чисельна стабільність алгоритму забезпечується використанням комплексної арифметики подвійної точності та нормалізацією проміжних результатів для уникнення переповнення при великій кількості шарів (km може досягати кількох сотень).

Обчислювальна складність алгоритму становить O(m1 · km), де m1 – кількість точок кутової сітки (типово 700), km – кількість підшарів (залежить від L1 та dl, типово 100-700). Для одної кривої з параметрами за замовчуванням час обчислення становить приблизно 50-100 мілісекунд на сучасному процесорному ядрі. Паралелізація на рівні генерації датасету (різні криві обчислюються незалежно на різних ядрах) дозволяє масштабувати продуктивність майже лінійно з кількістю доступних ядер.

## 3.3. Архітектура підсистеми підготовки даних

### 3.3.1. Стратегія генерації та структури даних

Підсистема підготовки даних реалізує два підходи до генерації навчальних датасетів: випадкове семплювання (модуль dataset.py) та стратифіковане семплювання (модуль dataset_stratified.py). Обидва підходи базуються на спільній архітектурній основі з різними реалізаціями етапу вибору комбінацій параметрів. Структура даних датасету представлена як пара тензорів PyTorch: X розміру [N, 7] містить нормалізовані значення параметрів для N зразків, Y розміру [N, 650] містить нормалізовані (log-transformed) значення інтенсивності кривих. Вибір формату pickle для серіалізації обумовлений балансом між розміром файлу, швидкістю завантаження та зручністю використання з PyTorch.

Діаграма класів підсистеми підготовки даних:

```
┌────────────────────────────────────────┐
│  ParameterRanges (Module-level const)  │
├────────────────────────────────────────┤
│ + DMAX1_RANGE = (0.001, 0.030)        │
│ + D01_RANGE = (0.002, 0.030)          │
│ + L1_RANGE = (1000e-8, 7000e-8)       │
│ + RP1_RANGE = (0, 7000e-8)            │
│ + D02_RANGE = (0.002, 0.030)          │
│ + L2_RANGE = (1000e-8, 7000e-8)       │
│ + RP2_RANGE = (-6000e-8, 0)           │
└────────────────────────────────────────┘
           │
           │ uses
           ▼
┌────────────────────────────────────────┐
│  _generate_single_sample               │
├────────────────────────────────────────┤
│ Вхід: (Dmax1, D01, L1, Rp1,            │
│        D02, L2, Rp2, dl)               │
│ Вихід: (params_normalized,             │
│         curve_normalized)              │
├────────────────────────────────────────┤
│ 1. Створити DeformationProfile        │
│ 2. Викликати compute_curve_and_profile│
│ 3. Усічення curve[start_ML:m1]        │
│ 4. Log-transform: log10(curve)        │
│ 5. Нормалізація до [0, 1]             │
│ 6. Нормалізація параметрів             │
│ RETURN (params_norm, curve_norm)       │
└────────────────────────────────────────┘
           │
           │ called by
           ▼
┌────────────────────────────────────────┐
│  generate_random_dataset               │  (dataset.py)
├────────────────────────────────────────┤
│ Вхід: n_samples, dl, n_workers         │
│ Вихід: (X_tensor, Y_tensor)            │
├────────────────────────────────────────┤
│ WHILE collected < n_samples:           │
│   1. Sample parameters uniformly       │
│   2. Validate constraints              │
│   3. IF valid: add to args_list        │
│ 4. Parallel processing with Pool       │
│ 5. Convert results to tensors          │
│ 6. Save to pickle file                 │
└────────────────────────────────────────┘

┌────────────────────────────────────────┐
│  build_valid_combinations_dict         │  (dataset_stratified.py)
├────────────────────────────────────────┤
│ Вихід: Dict[L2_value, List[combos]]   │
├────────────────────────────────────────┤
│ 1. Generate grids for all params       │
│    L2_grid = [500, 1000, ..., 5000] Å │
│    Rp2_grid = [-6000, -5500, ..., 0] Å│
│ 2. FOR each L2 in L2_grid:             │
│      combinations = []                 │
│      FOR all combos of other params:   │
│        IF validate_constraints():      │
│          ADD combo to combinations     │
│      grouped[L2] = combinations        │
│ RETURN grouped                         │
└────────────────────────────────────────┘
           │
           │ uses
           ▼
┌────────────────────────────────────────┐
│  stratified_sample                     │
├────────────────────────────────────────┤
│ Вхід: grouped_combinations, n_samples  │
│ Вихід: selected_combinations (List)    │
├────────────────────────────────────────┤
│ n_groups = len(grouped_combinations)   │
│ samples_per_group = n_samples // n_groups│
│ FOR each group in grouped:             │
│   IF len(group) >= samples_per_group:  │
│     indices = random_choice(           │
│               len(group),              │
│               size=samples_per_group)  │
│     selected += [group[i] for i in indices]│
│   ELSE:                                │
│     selected += group (all)            │
│ RETURN selected[:n_samples]            │
└────────────────────────────────────────┘
           │
           │ used by
           ▼
┌────────────────────────────────────────┐
│  generate_stratified_dataset           │
├────────────────────────────────────────┤
│ Вхід: n_samples, dl, n_workers         │
│ Вихід: (X_tensor, Y_tensor)            │
├────────────────────────────────────────┤
│ 1. grouped = build_valid_combinations()│
│ 2. selected = stratified_sample(       │
│               grouped, n_samples)      │
│ 3. args_list = prepare_args(selected)  │
│ 4. Parallel processing with Pool       │
│ 5. Convert results to tensors          │
│ 6. Verify distribution (Chi-squared)   │
│ 7. Save with '_balanced' postfix       │
└────────────────────────────────────────┘

┌────────────────────────────────────────┐
│  verify_distribution                   │
├────────────────────────────────────────┤
│ Вхід: X_tensor, dataset_name           │
│ Вихід: Chi-squared statistics (Dict)   │
├────────────────────────────────────────┤
│ FOR each parameter p in X:             │
│   unique_vals, counts = unique(X[:, p])│
│   expected = N / len(unique_vals)      │
│   chi_sq = sum((counts - expected)² /  │
│                 expected)              │
│   bias_ratio = max(counts) / min(counts)│
│   IF chi_sq < 10000:                   │
│     status = "PASS"                    │
│   ELSE:                                │
│     status = "FAIL"                    │
│   PRINT statistics                     │
└────────────────────────────────────────┘
```

Функція \_generate_single_sample є worker function для паралельної обробки: вона приймає один набір параметрів, викликає фізичний симулятор, виконує всі необхідні перетворення та повертає нормалізовану пару (параметри, крива). Ця функція визначена на рівні модуля (а не як метод класу) для сумісності з модулем multiprocessing, що вимагає серіалізації функцій через pickle. Внутрішньо функція створює об'єкт DeformationProfile з переданими параметрами, викликає compute_curve_and_profile, виконує усічення кривої (видалення перших start_ML=10 точок), застосовує логарифмічне перетворення log10(I) та нормалізацію інтенсивності до діапазону [0, 1] шляхом ділення на максимум.

Функція generate_random_dataset реалізує базовий підхід з випадковим семплюванням параметрів з рівномірних розподілів у визначених діапазонах та фільтрацією комбінацій, що порушують фізичні обмеження. Алгоритм працює в циклі: на кожній ітерації генерується кандидат комбінація параметрів, перевіряються обмеження (D01 ≤ Dmax1, L2 ≤ L1 тощо), і якщо комбінація валідна, вона додається до списку args_list. Цикл продовжується доки не накопичиться n_samples валідних комбінацій. Після цього список args_list подається на вхід multiprocessing.Pool для паралельного виконання \_generate_single_sample для кожної комбінації. Результати збираються, конвертуються в PyTorch тензори та зберігаються у pickle файл разом з метаданими (розмір датасету, параметр dl, timestamp тощо).

Функція generate_stratified_dataset реалізує вдосконалений підхід з гарантованою рівномірністю розподілу критичного параметра L2. Спочатку функція build_valid_combinations_dict генерує повний простір валідних комбінацій, згрупованих за значенням L2. Це досягається через вкладені цикли по дискретизованих сітках всіх параметрів: для кожного значення L2 з сітки [500, 1000, 1500, ..., 5000] Å перебираються всі можливі комбінації інших параметрів, і ті, що задовольняють обмеження (зокрема L2 ≤ L1), додаються до групи відповідного L2. Результат – словник, де ключі є значення L2, а значення – списки валідних комбінацій параметрів для даного L2.

Функція stratified_sample приймає цей словник та цільову кількість зразків n_samples, обчислює кількість зразків на групу samples_per_group = n_samples // n_groups (для 1 мільйона зразків та 10 груп L2 це 100,000 на групу), та для кожної групи випадково вибирає samples_per_group комбінацій з доступних у групі. Це гарантує, що кожне значення L2 буде представлене рівно samples_per_group разів у фінальному датасеті, забезпечуючи рівномірність розподілу з Chi-squared статистикою близькою до 0. Після вибору комбінацій алгоритм продовжується аналогічно до generate_random_dataset: паралельна генерація кривих, конвертація в тензори, збереження у pickle з постфіксом '\_balanced' для відрізнення від датасетів з випадковим семплюванням.

### 3.3.2. Паралелізація обчислень та оптимізація продуктивності

Генерація великомасштабних датасетів (порядку 1 мільйона зразків) є обчислювально інтенсивною задачею: кожна крива вимагає приблизно 50-100 мілісекунд процесорного часу, що в сумі дає 14-28 годин для послідовної генерації 1 мільйона кривих. Для скорочення часу генерації до прийнятних меж (2-3 години) критичною є ефективна паралелізація на всіх доступних процесорних ядрах. Система використовує модуль multiprocessing з стратегією process pool: при старті генерації створюється пул робочих процесів (за замовчуванням cpu_count() - 1, що залишає одне ядро для системних задач), кожен процес отримує підмножину комбінацій параметрів для обробки, і результати збираються в основному процесі.

Діаграма послідовності паралельної генерації датасету:

```
Main Process              Worker Process 1      Worker Process 2   ...   Worker Process N
     │                           │                     │                       │
     │ Create Pool(N)            │                     │                       │
     ├──────────────────────────►│                     │                       │
     ├───────────────────────────┼────────────────────►│                       │
     ├───────────────────────────┼─────────────────────┼──────────────────────►│
     │                           │                     │                       │
     │ Submit tasks              │                     │                       │
     │ (args_list[0])           │                     │                       │
     ├──────────────────────────►│                     │                       │
     │                           │ _generate_single_   │                       │
     │                           │  sample(args[0])    │                       │
     │                           │ ┌──────────────┐    │                       │
     │                           │ │ Physical sim │    │                       │
     │                           │ │ + transforms │    │                       │
     │                           │ └──────────────┘    │                       │
     │ (args_list[1])           │                     │                       │
     ├───────────────────────────┼────────────────────►│                       │
     │                           │                     │ _generate_single_     │
     │                           │                     │  sample(args[1])      │
     │                           │                     │ ┌──────────────┐      │
     │                           │                     │ │ Physical sim │      │
     │                           │                     │ │ + transforms │      │
     │ (args_list[N])           │                     │ └──────────────┘      │
     ├───────────────────────────┼─────────────────────┼──────────────────────►│
     │                           │                     │                       │
     │ ...                       │                     │                       │
     │                           │                     │                       │
     │◄──────────────────────────┤                     │                       │
     │  result[0]                │                     │                       │
     │                           │                     │                       │
     │◄───────────────────────────┼─────────────────────┤                       │
     │  result[1]                │                     │                       │
     │                           │                     │                       │
     │◄───────────────────────────┼─────────────────────┼───────────────────────┤
     │  result[N]                │                     │                       │
     │                           │                     │                       │
     │ Collect all results       │                     │                       │
     │ Convert to tensors        │                     │                       │
     │ Save to pickle            │                     │                       │
     │                           │                     │                       │
     │ Close Pool                │                     │                       │
     ├──────────────────────────►│                     │                       │
     ├───────────────────────────┼────────────────────►│                       │
     ├───────────────────────────┼─────────────────────┼──────────────────────►│
     │                           X                     X                       X
```

Ключовим елементом ефективної паралелізації є використання методу pool.imap_unordered замість pool.map: метод imap_unordered повертає результати в порядку завершення обчислень (а не в порядку вхідних даних), що дозволяє починати обробку результатів до завершення всіх задач та зменшує час очікування. Додатково, imap_unordered використовує lazy evaluation: задачі подаються у pool поступово по мірі звільнення робочих процесів, що зменшує пікове споживання пам'яті порівняно з map, що одразу серіалізує всі вхідні дані.

Обгортка результатів у tqdm (бібліотека для прогрес-барів) забезпечує візуалізацію прогресу генерації в консолі з оцінкою часу до завершення, що є критичним для довготривалих обчислень (генерація 1 мільйона зразків на 96 ядрах займає приблизно 2.5 години). Формат виводу tqdm: "Generating samples: 45% | 450000/1000000 [01:15<01:30, 5200 samples/s]", де 01:15 – час від початку, 01:30 – оцінка часу, що залишився, 5200 samples/s – поточна швидкість обробки.

Додаткова оптимізація стосується мінімізації overhead від серіалізації даних між процесами. Модуль multiprocessing використовує pickle для серіалізації аргументів функцій та результатів, що може стати вузьким місцем при великих обсягах даних. Для мінімізації цього ефекту функція \_generate_single_sample розроблена таким чином, щоб приймати мінімальний набір примітивних типів (float, int) замість складних об'єктів (класи), а повертати малі структури даних (список з 7 float для параметрів, масив NumPy з 650 float для кривої). Повні об'єкти DeformationProfile та Curve створюються всередині worker process і не передаються між процесами.

## 3.4. Архітектура підсистеми машинного навчання

### 3.4.1. Модульна структура нейронної мережі

Архітектура нейронної мережі побудована на принципах модульності та композиції: складна модель XRDRegressor конструюється з кількох багаторазово використовуваних компонентів (ResidualBlock, AttentionPool1d), кожен з яких реалізує специфічний аспект обробки даних. Такий підхід відповідає паттерну Composite з об'єктно-орієнтованого проектування та забезпечує гнучкість архітектури: для створення нової версії моделі достатньо змінити кількість блоків, їх параметри або порядок композиції без модифікації реалізації окремих компонентів.

Діаграма класів підсистеми машинного навчання:

```
┌─────────────────────────────────────────┐
│         nn.Module (PyTorch)             │
│         <<abstract>>                    │
├─────────────────────────────────────────┤
│ + forward(x): Tensor                    │  Абстрактний метод
│ + parameters(): Iterator                │  Ітератор по параметрах
│ + train() / eval(): void                │  Режими навчання/inference
└─────────────────────────────────────────┘
                    △
                    │ inherits
        ┌───────────┴───────────┬─────────────────────┐
        │                       │                     │
┌───────────────────┐  ┌────────────────────┐  ┌──────────────────┐
│  ResidualBlock    │  │  AttentionPool1d   │  │  XRDRegressor    │
├───────────────────┤  ├────────────────────┤  ├──────────────────┤
│ - c: int          │  │ - channels: int    │  │ - stem: Sequential│
│ - dilation: int   │  │ - attention: Seq   │  │ - block1-6: Res  │
│ - kernel_size: int│  │                    │  │ - trans1-5: Conv │
│ - conv1: Conv1d   │  ├────────────────────┤  │ - pool: Attention│
│ - bn1: BatchNorm  │  │ + forward(x):      │  │ - head: Sequential│
│ - conv2: Conv1d   │  │    Tensor          │  ├──────────────────┤
│ - bn2: BatchNorm  │  │                    │  │ + forward(x):    │
│ - act: ReLU       │  │ [B,C,L]→[B,C]     │  │    Tensor        │
├───────────────────┤  │ Attention-weighted │  │                  │
│ + forward(x):     │  │ pooling            │  │ [B,1,640]→[B,7] │
│    Tensor         │  └────────────────────┘  │                  │
│                   │                          │ Progressive ch:  │
│ [B,C,L]→[B,C,L]  │                          │ 32→48→64→96→    │
│ Identity skip    │                          │ 128→128          │
│ connection       │                          └──────────────────┘
└───────────────────┘                                  │
                                                       │ uses
                                                       ▼
                                        ┌──────────────────────────┐
                                        │ physics_constrained_loss │
                                        ├──────────────────────────┤
                                        │ Вхід: predictions,       │
                                        │       targets, weights   │
                                        │ Вихід: (loss, penalty)   │
                                        ├──────────────────────────┤
                                        │ 1. Base loss (Smooth L1) │
                                        │ 2. Constraint penalties: │
                                        │    - D01 ≤ Dmax1         │
                                        │    - L2 ≤ L1             │
                                        │    - Rp1 ≤ L1            │
                                        │    - D01+D02 ≤ 0.03      │
                                        │ 3. Total = base + 0.1*pen│
                                        └──────────────────────────┘
```

Клас ResidualBlock реалізує залишковий блок (residual block) – фундаментальний компонент глибоких CNN, що дозволяє навчати мережі з десятками шарів без проблеми затухання градієнта. Архітектура блоку включає два послідовних згорткових шари з пакетною нормалізацією та ReLU активацією між ними, плюс skip connection (пряме з'єднання), що додає вхід блоку до його виходу: output = F(input) + input, де F – це композиція conv-bn-relu-conv-bn. Параметри блоку включають кількість каналів c (константна на вході та виході), коефіцієнт розширення dilation для розширених згорток та розмір ядра kernel_size (типово 15 для версії v3).

Математично, для вхідного тензора x розміру [batch_size, channels, length], операція згортки з розширенням обчислюється як:

```
y[b, c_out, l] = Σ_{c_in} Σ_{k} w[c_out, c_in, k] · x[b, c_in, l + k·dilation] + bias[c_out]
```

де w – ваги фільтра розміру [c_out, c_in, kernel_size], k ∈ [0, kernel_size), dilation – коефіцієнт розширення. Для dilation=1 це стандартна згортка, для dilation=2 фільтр "бачить" кожну другу точку тощо. Це дозволяє експоненційно збільшувати рецептивне поле без збільшення кількості параметрів: блок з kernel_size=15 та dilation=32 має ефективне рецептивне поле 15 + (15-1)·32 = 463 точки.

Клас AttentionPool1d реалізує механізм уваги для агрегації просторової інформації в компактне представлення. На відміну від Global Average Pooling, що обчислює просте середнє по всіх позиціях (всі позиції мають рівну вагу), attention pooling навчається вагам для кожної позиції: output = Σ_i α_i · x_i, де α_i = softmax(attention(x))\_i. Компонент attention реалізований як міні-мережа з двох згорткових шарів 1×1 (точкових згорток): перший проектує channels-вимірні ознаки в channels/4-вимірний простір з ReLU активацією, другий проектує в 1-вимірний простір (logits для softmax). Така архітектура дозволяє моделі навчитися складним нелінійним функціям уваги в залежності від вмісту вхідного сигналу.

Клас XRDRegressor є центральною моделлю системи, що композує описані компоненти в послідовність обробки. Архітектура версії v3 організована наступним чином:

1. **Stem** (вхідний шар): Conv1d(1→32, kernel=9) + BatchNorm + ReLU. Проектує 1-канальний вхід (крива інтенсивності) у 32-канальне уявлення. Kernel size 9 обрано як компроміс між локальністю та достатнім рецептивним полем для початкового шару.

2. **Feature extraction (6 residual blocks з прогресивним розширенням каналів):**

   - Block 1: ResidualBlock(32, dilation=1, K=15)
   - Transition 1: Conv1d(32→48, kernel=1) – pointwise projection
   - Block 2: ResidualBlock(48, dilation=2, K=15)
   - Transition 2: Conv1d(48→64, kernel=1)
   - Block 3: ResidualBlock(64, dilation=4, K=15)
   - Transition 3: Conv1d(64→96, kernel=1)
   - Block 4: ResidualBlock(96, dilation=8, K=15)
   - Transition 4: Conv1d(96→128, kernel=1)
   - Block 5: ResidualBlock(128, dilation=16, K=15)
   - Transition 5: Conv1d(128→128, kernel=1)
   - Block 6: ResidualBlock(128, dilation=32, K=15)

3. **Pooling**: AttentionPool1d(128) – агрегація просторової інформації в 128-вимірний вектор.

4. **Head** (регресійна голова): Linear(128→256) + ReLU + Dropout(0.2) + Linear(256→128) + ReLU + Dropout(0.2) + Linear(128→7) + Sigmoid. Проектує ознаки в 7-вимірний простір нормалізованих параметрів. Sigmoid активація на виході забезпечує значення в діапазоні [0, 1].

Загальна кількість параметрів моделі становить приблизно 1.5 мільйона, що є помірним для сучасних стандартів та дозволяє ефективно навчатись на датасетах порядку 1 мільйона зразків без значного перенавчання.

### 3.4.2. Цикл навчання та управління експериментами

Процес навчання моделі організований як ітеративний цикл по епохах, де кожна епоха складається з повного проходу по навчальній вибірці (training phase) з оновленням параметрів моделі та валідаційного проходу (validation phase) без оновлення параметрів для оцінки якості поточної моделі. Детальна блок-схема циклу навчання:

```
START TRAINING
  │
  ▼
┌─────────────────────────────────────┐
│ 1. Initialization                   │
│ - Load dataset (X, Y)               │
│ - Train/Val split (95:5)            │
│ - Create DataLoaders (batch=256)    │
│ - Initialize model XRDRegressor()   │
│ - Initialize optimizer AdamW(       │
│   lr=0.002, weight_decay=5e-4)      │
│ - Initialize scheduler              │
│   ReduceLROnPlateau(patience=5)     │
│ - best_val_loss = ∞                 │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ FOR epoch = 1 TO max_epochs:        │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2. TRAINING PHASE                   │
│ model.train()  # Enable dropout/BN  │
│ train_loss_sum = 0                  │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ FOR batch in train_dataloader:      │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2.1. Load batch                     │
│      curves, params = batch         │
│      curves, params → device (GPU)  │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2.2. Forward pass                   │
│      predictions = model(curves)    │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2.3. Compute loss                   │
│      loss, penalty =                │
│        physics_constrained_loss(    │
│          predictions, params,       │
│          loss_weights)              │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2.4. Backward pass                  │
│      optimizer.zero_grad()          │
│      loss.backward()  # Compute ∇L  │
│      optimizer.step() # Update θ    │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 2.5. Accumulate statistics          │
│      train_loss_sum += loss * batch │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ NEXT batch                          │
│ train_loss = train_loss_sum / N_train│
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 3. VALIDATION PHASE                 │
│ model.eval()  # Disable dropout/BN  │
│ val_loss_sum = 0                    │
│ with torch.no_grad():  # No gradients│
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ FOR batch in val_dataloader:        │
│   curves, params = batch            │
│   predictions = model(curves)       │
│   loss, penalty =                   │
│     physics_constrained_loss(...)   │
│   val_loss_sum += loss * batch_size │
│ NEXT batch                          │
│ val_loss = val_loss_sum / N_val     │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 4. Update learning rate scheduler   │
│ scheduler.step(val_loss)            │
│ IF val_loss not improved for 5 epochs:│
│   lr = lr * 0.5                     │
│   IF lr < 1e-6: lr = 1e-6  # Clamp  │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 5. Checkpoint saving (early stopping)│
│ IF val_loss < best_val_loss:        │
│   best_val_loss = val_loss          │
│   SAVE checkpoint:                  │
│     - model.state_dict()            │
│     - epoch number                  │
│     - val_loss                      │
│     - optimizer state (optional)    │
│   PRINT "→ Saved best model"        │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ 6. Logging                          │
│ IF epoch % 10 == 0:                 │
│   PRINT "Epoch {epoch}/{max}       │
│          train: {train_loss:.5f}    │
│          val: {val_loss:.5f}        │
│          constraint: {penalty:.4f}  │
│          lr: {current_lr:.2e}"      │
│ ELSE:                               │
│   PRINT (without constraint)        │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ NEXT epoch                          │
└─────────────────────────────────────┘
  │
  ▼
┌─────────────────────────────────────┐
│ END TRAINING                        │
│ - Load best checkpoint              │
│ - Evaluate on test set              │
│ - Compute final metrics             │
└─────────────────────────────────────┘
  │
  ▼
END
```

Ключовими елементами циклу навчання є:

**Backward propagation (зворотне поширення помилки)**: метод loss.backward() автоматично обчислює градієнти функції втрат відносно всіх параметрів моделі через механізм автоматичного диференціювання PyTorch. Внутрішньо PyTorch будує обчислювальний граф операцій під час forward pass та використовує правило ланцюга для обчислення часткових похідних ∂L/∂θ для кожного параметра θ. Ці градієнти зберігаються у полі .grad кожного параметра та використовуються оптимізатором для оновлення ваг.

**Оновлення параметрів (optimizer.step())**: метод реалізує одну ітерацію алгоритму AdamW. Для кожного параметра θ обчислюються перший та другий моменти градієнта (експоненційно згладжені середнє та дисперсія градієнтів з попередніх ітерацій), на основі яких визначається адаптивна швидкість навчання для даного параметра. Формули оновлення:

```
m_t = β₁ · m_{t-1} + (1 - β₁) · ∇L
v_t = β₂ · v_{t-1} + (1 - β₂) · (∇L)²
θ_t = θ_{t-1} - η · m_t / (√v_t + ε) - λ · θ_{t-1}
```

де β₁=0.9, β₂=0.999 (параметри моментів), η – швидкість навчання, λ – коефіцієнт weight decay, ε=10⁻⁸ (для чисельної стабільності).

**Checkpoint management**: після кожної епохи, де валідаційні втрати покращились порівняно з попереднім найкращим значенням, повний стан моделі (словник з вагами всіх шарів) зберігається у файл через torch.save. Формат checkpoint файлу – словник Python з ключами: 'model' (state_dict моделі), 'epoch' (номер епохи), 'val_loss' (валідаційні втрати), 'L' (довжина вхідної послідовності для перевірки сумісності). Це дозволяє відновити модель точно в тому стані, в якому вона була на моменті найкращої валідаційної якості, навіть якщо навчання продовжувалось ще кілька десятків епох після цього моменту.

**Логування та моніторинг**: на кожній епосі виводиться рядок зі статистикою навчання для візуального контролю прогресу. Формат логу: "Epoch 065/100 | train: 0.01523 | val: 0.01389 | constraint: 0.0000 | lr: 5.00e-04". Додатково, кожні 10 епох виводиться constraint penalty для контролю частоти порушень фізичних обмежень (в успішно навченій моделі має бути близько 0). Для більш детального аналізу динаміки навчання можна інтегрувати інструменти, такі як TensorBoard або Weights & Biases, що дозволяють візуалізувати графіки втрат, розподіли ваг, активацій тощо в інтерактивному веб-інтерфейсі.

## 3.5. Організація збереження та обміну даними

### 3.5.1. Формати даних та файлова структура

Система використовує кілька форматів даних для різних типів інформації, кожен оптимізований для свого призначення. Датасети зберігаються у форматі pickle (Python serialization), що забезпечує швидке збереження та завантаження складних Python об'єктів (тензори PyTorch, NumPy масиви, словники метаданих) без необхідності ручної серіалізації кожного поля. Checkpoint файли моделей також використовують pickle (через torch.save, що внутрішньо використовує pickle) з додатковою оптимізацією для тензорів через формат PyTorch Tensor Storage. Конфігураційні параметри (діапазони варіювання параметрів, гіперпараметри навчання) жорстко закодовані як константи на рівні модулів для спрощення відтворюваності експериментів.

Структура директорій проекту організована за принципом separation of concerns:

```
master-project-light/
│
├── datasets/                          # Згенеровані датасети
│   ├── dataset_1000_dl100_balanced.pkl       (2.5 MB)
│   ├── dataset_10000_dl100_jit.pkl           (25 MB)
│   ├── dataset_100000_dl400.pkl              (251 MB)
│   ├── dataset_1000000_dl100_balanced.pkl    (2.5 GB)
│   └── dataset_1000000_dl400_jit.pkl         (2.4 GB)
│
├── checkpoints/                       # Збережені моделі
│   ├── dataset_100000_dl400_v2.pt            (~6 MB)
│   ├── dataset_1000000_dl100_balanced_v3.pt  (~6 MB)
│   └── ...
│
├── xrd.py                            # Фізичне моделювання
├── dataset_stratified.py             # Генерація з stratified sampling
├── dataset.py                        # Генерація з random sampling
├── model_common.py                   # Архітектура моделі
├── model_train.py                    # Цикл навчання
├── model_evaluate.py                 # Оцінка моделі
├── helpers.py                        # Допоміжні функції
│
├── docs/                             # Документація
│   ├── DATASET_BIAS_ANALYSIS.md
│   ├── ARCHITECTURE_IMPROVEMENTS_PLAN.md
│   ├── COMPARISON_WITH_ZIEGLER.md
│   ├── CURVE_TRUNCATION_ANALYSIS.md
│   ├── V3_ARCHITECTURE_SUMMARY.md
│   └── 1M_DATASET_COMPARISON.md
│
├── venv/                             # Віртуальне середовище Python
├── requirements.txt                  # Залежності
└── README.md                         # Опис проекту
```

Формат pickle файлу датасету представляє словник Python з наступною структурою:

```python
dataset = {
    'X': np.ndarray,        # Shape: (N, 7), dtype: float32
                           # Нормалізовані параметри [0, 1]
                           # Порядок: [Dmax1, D01, L1, Rp1, D02, L2, Rp2]

    'Y': np.ndarray,        # Shape: (N, 640), dtype: float32
                           # Log-нормалізовані криві інтенсивності

    'n_samples': int,       # Кількість зразків N

    'dl': float,            # Товщина підшару (см)

    'dl_angstrom': int,     # Товщина підшару (Å) для імені файлу

    'sampling_method': str, # 'random' або 'stratified_balanced'

    'timestamp': str,       # ISO формат, напр. '2025-10-29T18:30:00'

    'device': str,          # 'cpu', 'cuda:0', або 'mps'

    'grid_info': {          # Метадані про дискретизацію (для stratified)
        'L2_step': int,     # Крок сітки для L2 (Å)
        'Rp2_step': int,    # Крок сітки для Rp2 (Å)
        'note': str
    }
}
```

Формат checkpoint файлу моделі:

```python
checkpoint = {
    'model': OrderedDict,   # state_dict з вагами всіх шарів
                           # Ключі: 'stem.0.weight', 'block1.conv1.weight', ...
                           # Значення: torch.Tensor

    'epoch': int,           # Номер епохи найкращої моделі

    'val_loss': float,      # Валідаційні втрати на цій епосі

    'L': int,               # Довжина вхідної послідовності (640)
                           # Для перевірки сумісності
}
```

Розмір checkpoint файлу (~6 MB для моделі з 1.5M параметрів) визначається кількістю параметрів моделі та точністю їх збереження (32-бітні float за замовчуванням). Для зменшення розміру можна використовувати 16-бітну точність (half precision), що скорочує розмір вдвічі з мінімальною втратою точності inference.

### 3.5.2. API для завантаження даних та моделей

Для зручного доступу до даних та моделей розроблено набір функцій-утиліт з чіткими інтерфейсами та обробкою помилок. Ключові функції API описані нижче:

**Завантаження датасету:**

```python
def load_dataset(path: Path) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Завантажити датасет з pickle файлу.

    Args:
        path: Шлях до .pkl файлу

    Returns:
        (X, Y): X - параметри [N, 7], Y - криві [N, 640]

    Raises:
        FileNotFoundError: якщо файл не існує
        ValueError: якщо формат файлу некоректний
    """
    if not path.exists():
        raise FileNotFoundError(f"Dataset not found: {path}")

    with open(path, 'rb') as f:
        data = pickle.load(f)

    # Валідація формату
    required_keys = ['X', 'Y', 'n_samples']
    for key in required_keys:
        if key not in data:
            raise ValueError(f"Invalid dataset format: missing key '{key}'")

    # Конвертація NumPy → PyTorch якщо потрібно
    X = torch.from_numpy(data['X']) if isinstance(data['X'], np.ndarray) \
        else data['X']
    Y = torch.from_numpy(data['Y']) if isinstance(data['Y'], np.ndarray) \
        else data['Y']

    return X, Y
```

**Завантаження моделі:**

```python
def load_model(checkpoint_path: Path,
               device: torch.device = None) -> XRDRegressor:
    """
    Завантажити натреновану модель з checkpoint файлу.

    Args:
        checkpoint_path: Шлях до .pt файлу
        device: Пристрій для inference (None = auto-detect)

    Returns:
        model: Завантажена модель у режимі eval()

    Raises:
        FileNotFoundError: якщо файл не існує
        RuntimeError: якщо архітектура несумісна
    """
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")

    if device is None:
        device = get_device()

    checkpoint = torch.load(checkpoint_path, map_location=device)

    # Перевірка сумісності
    expected_L = 640
    if checkpoint.get('L', expected_L) != expected_L:
        raise RuntimeError(
            f"Incompatible model: expected input length {expected_L}, "
            f"got {checkpoint['L']}"
        )

    # Створити модель та завантажити ваги
    model = XRDRegressor().to(device)
    model.load_state_dict(checkpoint['model'])
    model.eval()  # Режим inference (disable dropout/batchnorm training)

    return model
```

**Dataset класс для PyTorch DataLoader:**

```python
class NormalizedXRDDataset(Dataset):
    """
    PyTorch Dataset для XRD даних з pickle файлів.

    Виконує on-the-fly перетворення:
    - Log-transform для XRD кривих (якщо log_space=True)
    - Нормалізація до [0, 1]
    - Опціональна аугментація для train режиму
    """

    def __init__(self,
                 X: torch.Tensor,
                 Y: torch.Tensor,
                 log_space: bool = True,
                 train: bool = False):
        """
        Args:
            X: Параметри [N, 7]
            Y: Криві [N, 640] (вже log-transformed та нормалізовані)
            log_space: Застосувати log10 (якщо ще не застосовано)
            train: Режим навчання (для аугментації)
        """
        self.X = X
        self.Y = Y
        self.log_space = log_space
        self.train = train

    def __len__(self) -> int:
        return self.X.size(0)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Повертає пару (curve, params) для індексу idx.

        Returns:
            curve: [1, 640] - 1-канальна крива
            params: [7] - нормалізовані параметри
        """
        params = self.X[idx]
        curve = self.Y[idx]

        # Додати channel dimension
        curve = curve.unsqueeze(0)  # [640] → [1, 640]

        # Опціональна аугментація в train режимі
        if self.train:
            # Можна додати шум, масштабування тощо
            pass

        return curve, params
```

**Денормалізація передбачень:**

```python
def denorm_params(params_normalized: torch.Tensor) -> torch.Tensor:
    """
    Перетворити нормалізовані параметри [0, 1] назад у фізичні одиниці.

    Args:
        params_normalized: Тензор [N, 7] у діапазоні [0, 1]

    Returns:
        params_physical: Тензор [N, 7] у фізичних одиницях
                        [Dmax1, D01, L1(см), Rp1(см), D02, L2(см), Rp2(см)]
    """
    RANGES = [
        (0.001, 0.030),      # Dmax1
        (0.002, 0.030),      # D01
        (1000e-8, 7000e-8),  # L1 (см)
        (0, 7000e-8),        # Rp1 (см)
        (0.002, 0.030),      # D02
        (1000e-8, 7000e-8),  # L2 (см)
        (-6000e-8, 0),       # Rp2 (см)
    ]

    params_physical = params_normalized.clone()
    for i, (min_val, max_val) in enumerate(RANGES):
        params_physical[:, i] = (params_normalized[:, i] * (max_val - min_val)
                                 + min_val)

    return params_physical
```

Ці API функції забезпечують консистентний інтерфейс для всіх компонентів системи та інкапсулюють деталі формату даних, що спрощує майбутні зміни формату (наприклад, перехід з pickle на HDF5) без модифікації клієнтського коду.

## 3.6. Шаблони проектування та архітектурні рішення

### 3.6.1. Застосовані шаблони проектування

В процесі розробки системи застосовано кілька класичних шаблонів проектування (design patterns), що підвищують модульність, розширюваність та підтримуваність коду:

**1. Facade (Фасад)** - використано для спрощення інтерфейсу складної підсистеми фізичного моделювання. Функція compute_curve_and_profile приховує від клієнта деталі створення об'єктів CrystalParameters, FilmParameters, GeometryParameters, HRXRDSimulator та послідовності виклику методів Start(), Profil(), PolarizationInit(), RozrachKogerTT(), Zgortka(). Клієнт просто передає масив параметрів деформації та отримує готові об'єкти Curve і Profile. Це знижує зв'язність між підсистемами та дозволяє змінювати внутрішню реалізацію симулятора без впливу на клієнтський код.

**2. Strategy (Стратегія)** - реалізовано для вибору методу генерації датасету. Інтерфейс generate_dataset приймає параметр strategy: str, який може бути 'random' або 'stratified', та викликає відповідну функцію generate_random_dataset або generate_stratified_dataset. Обидві функції мають ідентичну сигнатуру (приймають n_samples, dl, n_workers) та повертають однаковий формат результату (X, Y), що дозволяє прозоро змінювати стратегію без модифікації коду, що використовує датасети.

**3. Template Method (Шаблонний метод)** - алгоритм навчання реалізовано як шаблон з фіксованою структурою (ініціалізація → цикл по епохах → для кожної епохи: training phase → validation phase → update scheduler → save checkpoint → logging) з можливістю кастомізації окремих кроків через параметри або callback функції. Наприклад, функція втрат передається як параметр, що дозволяє легко експериментувати з різними варіантами (MSE, MAE, physics-constrained) без зміни основного циклу.

**4. Composite (Компонувальник)** - архітектура нейронної мережі побудована як дерево об'єктів, де складні модулі (XRDRegressor) складаються з простіших модулів (ResidualBlock, AttentionPool1d), які в свою чергу складаються з примітивних операцій (Conv1d, BatchNorm1d, ReLU). Всі компоненти наслідуються від базового класу nn.Module та реалізують уніфікований інтерфейс forward(x), що дозволяє рекурсивно застосовувати операції до вкладених компонентів та автоматично обчислювати градієнти для всієї ієрархії.

**5. Factory (Фабрика)** - функції create_GGG_crystal(), create_YIG_film() діють як фабричні методи, що інкапсулюють логіку створення складних об'єктів CrystalParameters та FilmParameters з багатьма полями. Замість того, щоб клієнт безпосередньо викликав конструктор з десятком параметрів (що є схильним до помилок), він викликає фабричну функцію без параметрів, яка повертає преконфігурований об'єкт для стандартної системи GGG+YIG. Це також забезпечує центральне місце для зміни параметрів: якщо потрібно змінити, наприклад, параметр ґратки GGG, достатньо модифікувати одну фабричну функцію замість пошуку всіх місць створення об'єкта.

**6. Singleton (Одинак)** - патерн неявно реалізований для управління пристроєм (device) через функцію get_device(), що при першому виклику детектує доступні апаратні прискорювачі (CUDA, MPS) та кешує результат для подальших викликів. Це гарантує, що всі компоненти системи (модель, дані, оптимізатор) використовують один і той самий пристрій, запобігаючи помилкам, пов'язаним з передачею тензорів між різними пристроями.

### 3.6.2. Принципи чистої архітектури

Розробка системи керувалася принципами чистої архітектури (Clean Architecture) та SOLID принципами об'єктно-орієнтованого проектування:

**Single Responsibility Principle (SRP)** - кожен модуль має чітко визначену єдину відповідальність: xrd.py відповідає виключно за фізичне моделювання, dataset_stratified.py – за генерацію датасетів, model_common.py – за архітектуру моделі, model_train.py – за процес навчання. Це забезпечує низьку зв'язність між модулями та спрощує тестування та модифікацію окремих компонентів.

**Open/Closed Principle (OCP)** - система відкрита для розширення, але закрита для модифікації. Наприклад, для додавання нової версії моделі (v4) не потрібно модифікувати існуючі класи ResidualBlock або AttentionPool1d – достатньо створити новий клас XRDRegressor_v4, що композує ці компоненти по-новому. Аналогічно, для додавання нової стратегії семплювання не потрібно змінювати існуючі функції – достатньо реалізувати нову функцію generate_custom_dataset з відповідною сигнатурою.

**Dependency Inversion Principle (DIP)** - високорівневі модулі (model_train.py) не залежать від деталей низькорівневих модулів (конкретної реалізації DataLoader), а залежать від абстракцій (інтерфейсу Dataset). Це дозволяє замінити реалізацію NormalizedXRDDataset на альтернативну (наприклад, HDF5Dataset) без зміни коду навчання, якщо нова реалізація відповідає тому ж інтерфейсу.

**Separation of Concerns** - фізичне моделювання, підготовка даних, машинне навчання та інференс організовані як окремі підсистеми з мінімальними залежностями. Це відповідає концепції layered architecture: фізичний шар (xrd.py) не знає про існування ML шару (model_common.py), ML шар не знає про деталі фізичних обчислень, а обидва не залежать від конкретного формату збереження даних (pickle).

**Explicit is better than implicit** (з Zen of Python) - всі критичні параметри (діапазони варіювання параметрів, гіперпараметри навчання, архітектурні константи) явно визначені як іменовані константи на рівні модулів замість магічних чисел в коді. Це підвищує читабельність та полегшує налаштування системи. Наприклад, замість model = XRDRegressor(64, 6, [1,2,4,8,16,32]) використовується model = XRDRegressor(), де всі параметри визначені всередині класу з документованими значеннями за замовчуванням.

## 3.7. Перспективи розширення системи

Архітектура системи спроектована з урахуванням можливих напрямків майбутнього розширення функціональності. Модульна організація та дотримання принципів чистої архітектури забезпечують можливість додавання нових функцій з мінімальною модифікацією існуючого коду. Основні напрямки розширення включають інтеграцію з експериментальними установками для аналізу в реальному часі, впровадження механізмів оцінки невизначеності передбачень для визначення confidence intervals, розширення методу на багатошарові гетероструктури з різким складом та розробку веб-інтерфейсу для доступу до моделі без необхідності встановлення Python середовища.

Для інтеграції з дифрактометрами необхідно розробити адаптер, що підключається до програмного забезпечення дифрактометра (зазвичай через COM/DCOM інтерфейси на Windows або TCP/IP сокети), отримує XRD-криві в реальному часі після завершення сканування, нормалізує їх до формату, очікуваного моделлю, викликає inference та відображає результати (передбачені параметри та відновлений профіль деформації) в графічному інтерфейсі. Критичною вимогою є швидкість inference (має бути менше часу сканування, типово 5-30 хвилин), що легко досягається навіть на CPU (inference займає < 1 секунди).

Оцінка невизначеності може бути реалізована через ансамблі моделей (train кілька моделей з різними random seeds та обчислювати дисперсію їх передбачень) або через Bayesian neural networks з dropout inference (залишати dropout активним під час inference та робити кілька forward passes для отримання розподілу передбачень). Це дозволить надавати користувачу не тільки точкові оцінки параметрів, але й інтервали довіри, що є критичним для наукових застосувань.

Розширення на багатошарові системи вимагає модифікації як фізичної моделі (врахування різких меж між шарами з різними параметрами ґратки та складом), так і архітектури CNN (можливо, з використанням механізмів сегментації для ідентифікації кількості та позицій меж між шарами). Для навчання такої моделі необхідно генерувати датасети з варіабельною кількістю шарів (від 1 до, наприклад, 5), що створює додаткові виклики для архітектури (як обробляти вхідні дані змінної структури) та може вимагати застосування рекурентних або трансформер-подібних архітектур замість чистих CNN.
