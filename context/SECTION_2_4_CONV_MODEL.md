# 2.4 Згорткова модель для аналізу КДВ

Криві дифракційного відбивання розглядаються як одномірні сигнали зі складною структурою: різко виражений пік несе інформацію про стан приповерхневого шару, тоді як протяжні інтерференційні осциляції відображають товщини та градієнти деформації на глибині. Саме поєднання локальних і глобальних компонент задає вимоги до моделі, здатної бачити як ближній, так і далекий контекст без втрати чутливості до деталей. Згорткові нейронні мережі у цій ролі дають інваріантність до невеликих зсувів і дозволяють відтворювати повторювані патерни, характерні для КДВ, незалежно від їхнього положення на осі кутів.

Вибір 1D-CNN виправданий кількома властивостями. По-перше, згортки лінійно масштабуються з довжиною вхідного сигналу і кількістю каналів, тож їх можна ефективно застосовувати до великих наборів синтетичних кривих без різкого зростання числа параметрів. По-друге, ширина рецептивного поля можна регулювати: невеликі ядра добре відтворюють форму піка, а дилатовані згортки дозволяють охоплювати інтерференційні хвости без додаткових шарів. Це забезпечує баланс між описом локальної форми і глобальної періодичності, що критично для відновлення параметрів деформаційного профілю.

Архітектурно доцільно включити до вхідних даних не лише інтенсивність, а й нормовану позиційну координату точки кривої. Такий другий канал зберігає чутливість моделі до абсолютного розташування піків, не руйнуючи корисну трансляційну інваріантність згорток. Це важливо для точного визначення параметрів, що відповідають за положення максимумів деформації, і зменшує ризик змішування близьких за впливом, але різних за координатою сценаріїв.

Багатомасштабність є центральною властивістю майбутньої моделі. Планується поєднувати короткі ядра для моделювання форми піка з дилатаціями, що збільшують ефективне рецептивне поле й дозволяють «бачити» далекі осциляції, пов’язані з товщинами шарів. Такий підхід дає змогу відтворювати спільні закономірності, не збільшуючи неконтрольовано кількість параметрів, і утримує розумний компроміс між глибиною мережі та її збіжністю.

Залишкові з’єднання вважаються базовим механізмом стабілізації навчання. Вони пом’якшують проблему згасання градієнта і дають можливість нарощувати кількість блоків, зберігаючи здатність моделі уловлювати тонкі варіації кривої. Для задачі відновлення параметрів деформаційного профілю це особливо важливо, адже різниця між близькими зразками може проявлятися в дрібних зморшках сигналу.

Механізми уваги розглядаються як альтернатива глобальному усередненню. Навчена увага може підсилювати ті ділянки кривої, що несуть найбільше інформації про позицію та амплітуду деформаційних максимумів, залишаючи шумові сегменти з низькими вагами. Це потенційно знижує чутливість до флуктуацій фону і робить прогнозування координат піків більш стабільним.

Опційне доповнення — спектральна гілка, що працює у просторі перетворення Фур’є або вейвлетів. Період осциляцій у хвостовій частині кривої прямо корелює з товщинами шарів, і явне кодування цієї періодичності може підвищити точність оцінки геометричних параметрів. Об’єднання просторових і спектральних представлень у спільному просторі ознак дозволить моделі спиратися на різні індуктивні припущення, підсилюючи стійкість до доменного зсуву між синтетичними та експериментальними КДВ.

Передобробка даних повинна підтримувати баланс між збереженням фізичного змісту і зниженням варіативності, не пов’язаної з параметрами. Логарифмування інтенсивності підсилює видимість слабких хвостів, вирівнювання за максимумом скорочує випадкові зміщення, а відсікання шумового фону у хвості зменшує вплив експериментального шуму. Нормалізація довжини кривої через інтерполяцію або підрізання створює сталі умови для формування батчів, що полегшує навчання згорткового тракту.

Фізичні зв’язки між параметрами мають бути інтегровані у процес навчання, щоб уникати нефізичних прогнозів. Обмеження на співвідношення деформацій, сумарну деформацію та взаємне розташування максимумів і товщин шарів можуть бути закладені у функцію втрат або у саму параметризацію виходу. Така інтеграція дозволяє зменшити потребу у жорсткому постпроцесінгу та погоджує результат моделі із фізичними законами системи.

Переваги згорткового підходу проявляються у стійкості до дрібних зсувів, масштабованості на великі синтетичні набори та можливості інтерпретувати значущі зони кривої через карти уваги або активації. Водночас існують ризики: залежність від коректної нормалізації, потенційний доменний зсув між моделлю та експериментом, а також недооцінка рідко представлених крайніх значень у разі незбалансованого набору. Ці фактори потрібно враховувати при формуванні датасету і при виборі стратегії регуляризації.

Стратегія навчання має поєднувати регресійні втрати (наприклад, MAE чи Smooth L1) із фізично мотивованими штрафами за порушення ключових нерівностей. Аугментації, що імітують зміни фону, невеликі зсуви піка чи варіації інтенсивності, допоможуть підвищити робастність, за умови що вони не руйнують фізичні обмеження. Моніторинг метрик по кожному параметру окремо дозволить вчасно виявляти перекоси й коригувати навчання, а регуляризація зменшить ризик перенавчання на випадкових флуктуаціях.

Для дисертаційної подачі доцільно підготувати схематичні ілюстрації, що показують співіснування локальних і глобальних патернів (умовна «Рис. 2.4.1»), концептуальну схему згорткової моделі з увагою та спектральною гілкою («Рис. 2.4.2») і приклад розкладання кривої у просторі ознак («Рис. 2.4.3»). Ці візуальні опори допоможуть читачеві пов’язати теоретичні аргументи з подальшими рішеннями.

Сформульовані положення цього підрозділу створюють основу для проектування архітектури у третьому розділі, де буде узгоджено компоненти системи та їхні взаємодії. Надалі, у четвертому розділі, ці принципи перетворяться на конкретні реалізації й експериментальні протоколи, що дозволять оцінити практичну ефективність згорткового підходу для автоматизованого визначення параметрів деформаційного профілю за КДВ.
